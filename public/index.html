<!DOCTYPE html>
<html lang="nl">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cyber-Agent v1.0 | Agentic UI</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Space+Mono&display=swap" rel="stylesheet">
    <style>
        body {
            background: #050505;
            font-family: 'Space Mono', monospace;
            overflow: hidden;
        }

        .neon-text {
            text-shadow: 0 0 10px #00ffff, 0 0 20px #00ffff;
        }

        .glitch-border {
            border: 1px solid #ff00ff;
            box-shadow: 0 0 15px rgba(255, 0, 255, 0.3);
        }

        #canvas-overlay {
            pointer-events: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: repeating-linear-gradient(0deg, rgba(0, 0, 0, 0.15) 0px, rgba(0, 0, 0, 0.15) 1px, transparent 1px, transparent 2px);
        }
    </style>
</head>

<body class="flex flex-col items-center justify-center min-h-screen p-4 text-cyan-400">

    <div id="canvas-overlay"></div>

    <!-- Agent Interface -->
    <div class="relative z-10 flex flex-col items-center">
        <svg width="300" height="300" viewBox="0 0 200 200" id="agent-svg">
            <defs>
                <filter id="glow">
                    <feGaussianBlur stdDeviation="2.5" result="coloredBlur" />
                    <feMerge>
                        <feMergeNode in="coloredBlur" />
                        <feMergeNode in="SourceGraphic" />
                    </feMerge>
                </filter>
            </defs>

            <!-- Hexagonal Frame -->
            <path id="frame" d="M 100 20 L 170 50 L 170 150 L 100 180 L 30 150 L 30 50 Z" fill="#0a0a0a"
                stroke="#00ffff" stroke-width="2" filter="url(#glow)" />

            <!-- Eyes -->
            <g id="eyes" filter="url(#glow)">
                <rect id="eye-l" x="65" y="85" width="25" height="4" fill="#ff00ff" />
                <rect id="eye-r" x="110" y="85" width="25" height="4" fill="#ff00ff" />
            </g>

            <!-- Lip-Sync Mouth -->
            <path id="mouth" d="M 70 135 L 130 135" stroke="#00ffff" stroke-width="3" fill="none" stroke-linecap="round"
                filter="url(#glow)" />
        </svg>

        <div class="mt-8 space-y-4 text-center">
            <h1 class="neon-text text-xl font-bold tracking-[0.3em]">CORE_AGENT_LINK</h1>
            <p id="status" class="text-[10px] text-magenta-500 opacity-70 italic uppercase">Status: Awaiting
                Initialization...</p>
            <div class="mt-1 flex gap-3 items-center justify-center">
                <div id="conn-state" class="text-[10px] text-cyan-300">conn: disconnected</div>
                <div id="ttl-indicator" class="text-[10px] text-yellow-300">ttl: -</div>
            </div>

            <input type="text" id="input-field" name="command" placeholder="COMMAND_INPUT_"
                class="glitch-border bg-transparent p-3 w-72 text-center text-cyan-400 focus:outline-none placeholder-cyan-900 transition-all">
        </div>
        <button id="start-btn" onclick="initCore()"
            class="mt-8 px-10 py-3 bg-cyan-900/20 border border-cyan-400 hover:bg-cyan-400 hover:text-black transition-all font-bold tracking-widest text-xs">
            INIT_SYSTEM_VOICE
        </button>
        <button id="mic-btn" title="Toggle microphone"
            class="ml-3 mt-8 px-3 py-2 bg-black/20 border border-cyan-400 text-xs">üé§</button>

        <div class="mt-4 w-80 text-left">
            <div id="transcript" class="glitch-border bg-black/30 p-3 h-36 overflow-auto text-sm text-cyan-200"></div>
            <div class="mt-2">
                <label class="text-xs text-cyan-300">System instructions (editable):</label>
                <textarea id="instruction-editor" rows="3"
                    class="w-full mt-1 p-2 text-xs bg-black/50 text-cyan-200 glitch-border"
                    placeholder="Edit instructions for testing..."></textarea>
                <div class="flex items-center gap-2 mt-1">
                    <input id="use-custom" type="checkbox" />
                    <label for="use-custom" class="text-xs text-cyan-300">Use custom instruction</label>
                </div>
            </div>
            <div class="mt-2 flex gap-2 justify-center">
                <button id="disconnect-btn"
                    class="px-3 py-1 bg-red-700/20 border border-red-500 text-xs">Disconnect</button>
                <button id="mute-btn" class="px-3 py-1 bg-yellow-700/20 border border-yellow-500 text-xs">Mute</button>
                <button id="reconnect-btn"
                    class="px-3 py-1 bg-green-700/20 border border-green-500 text-xs">Reconnect</button>
            </div>
        </div>
    </div>

    <script>
        const mouth = document.getElementById('mouth');
        const status = document.getElementById('status');
        const input = document.getElementById('input-field');

        document.body.addEventListener("click", () => audioCtx?.resume(), { once: true });



        // --- NIEUW: Realtime AI Koppeling ---
        // global nextStartTime so playAndVisualize can schedule audio chunks
        let nextStartTime = 0;

        // WS/audio globals
        let ws = null;
        let audioCtx = null;
        let analyser = null;
        let gainNode = null;
        let muted = false;
        let ttlInterval = null;

        function handleAudioChunk(base64) {
            playAndVisualize(base64);
        }


        async function initCore() {
            status.innerText = "Requesting_Ephemeral_Token...";

            try {
                // 1. Haal het beveiligde token op bij je Vercel API
                const startBtn = document.getElementById('start-btn');
                startBtn.disabled = true;

                const sessionResponse = await fetch("/api/session", { method: "POST" });
                if (!sessionResponse.ok) {
                    const txt = await sessionResponse.text();
                    status.innerText = "Error: Session endpoint failed";
                    console.error('session error', sessionResponse.status, txt);
                    startBtn.disabled = false;
                    return;
                }

                const sessionData = await sessionResponse.json();
                // sessionData should include client_secret.value when creating ephemeral keys
                const EPHEMERAL_KEY = sessionData?.client_secret?.value;

                // populate instruction editor with server-provided instructions for quick editing
                try {
                    const editor = document.getElementById('instruction-editor');
                    if (editor) editor.value = sessionData.instructions || editor.value || '';
                } catch (e) { /* ignore */ }

                if (!EPHEMERAL_KEY) {
                    status.innerText = "Error: No ephemeral key returned from /api/session";
                    console.error('session response', sessionData);
                    startBtn.disabled = false;
                    return;
                }

                // persist session data for later (user inputs)
                window._sessionData = sessionData;

                // start TTL timer if expiry provided
                if (sessionData?.client_secret?.expires_at) {
                    const expiresAt = Number(sessionData.client_secret.expires_at);
                    window._ephemeralExpires = expiresAt * 1000;
                    startTTLTimer(window._ephemeralExpires);
                }

                // update connection state
                updateConnectionState('connecting');

                // Optionally show expiry if present
                if (sessionData?.client_secret?.expires_at) {
                    const expires = new Date(sessionData.client_secret.expires_at * 1000);
                    status.innerText = `Ephemeral key acquired (expires ${expires.toLocaleTimeString()})`;
                }

                // 2. Start de WebSocket
                ws = new WebSocket(
                    "wss://api.openai.com/v1/realtime",
                    ["realtime", "openai-insecure-api-key." + EPHEMERAL_KEY, "openai-beta.realtime-v1"]
                );

                // 3. Audio Context voor AI-stem
                audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                try {
                    await audioCtx.resume(); // ensure audio is allowed after user gesture
                } catch (e) { /* ignore */ }
                analyser = audioCtx.createAnalyser();
                analyser.fftSize = 256;
                gainNode = audioCtx.createGain();
                analyser.connect(gainNode);
                gainNode.connect(audioCtx.destination);
                gainNode.gain.value = muted ? 0 : 1;

                ws.onopen = () => {
                    status.innerText = "System: Neural_Link_Established";
                    updateConnectionState('connected');
                    startBtn.classList.add('hidden');

                    // Stuur een welkomstbericht naar de AI
                    const customChecked = document.getElementById('use-custom')?.checked;
                    const editorVal = document.getElementById('instruction-editor')?.value;
                    const instructionToUse = (customChecked && editorVal) ? editorVal : (sessionData.instructions || "Je bent een cyberpunk AI-agent. Begroet de gebruiker kort en krachtig in het Nederlands.");

                    const event = {
                        type: "response.create",
                        response: {
                            modalities: ["audio", "text"],
                            instructions: instructionToUse,
                            audio: {
                                voice: "shimmer", format: "pcm16", sample_rate: 24000
                            },
                            speech: {
                                phoneme_timestamps: true
                            }
                        }
                    };
                    ws.send(JSON.stringify(event));
                };

                ws.onerror = (ev) => {
                    console.error('WebSocket error', ev);
                    status.innerText = 'WebSocket error';
                    updateConnectionState('error');
                    startBtn.disabled = false;
                };

                ws.onclose = (ev) => {
                    console.log('WebSocket closed', ev);
                    status.innerText = 'Connection closed';
                    updateConnectionState('disconnected');
                    startBtn.classList.remove('hidden');
                    startBtn.disabled = false;
                };
                // Luister naar de AI en beweeg de mond
                ws.onmessage = async (event) => {
                    let msg;
                    try {
                        msg = JSON.parse(event.data);
                    } catch {
                        return;
                    }

                    // --- AUDIO CHUNKS ---
                    if (msg.type === "response.audio.delta") {
                        handleAudioChunk(msg.delta);
                    }

                    // --- PHONEMES FOR LIPSYNC ---
                    if (msg.type === "response.audio.phoneme") {
                        animateMouthFromPhoneme(msg.phoneme);
                    }

                    // --- TEXT OUTPUT ---
                    if (msg.type === "response.output_text.delta") {
                        appendTranscript(msg.delta, "assistant");
                    }
                };

                // Start animatie loop voor de mond
                animateMouthFromAnalyser(analyser);

            } catch (e) {
                status.innerText = "Error: Link_Failed_Check_Logs";
                console.error(e);
            }

            // Functie om de mond te laten bewegen op de AI-stem
            function animateMouthFromAnalyser(analyser) {
                const dataArray = new Uint8Array(analyser.frequencyBinCount);

                function loop() {
                    analyser.getByteFrequencyData(dataArray);
                    const avg = dataArray.reduce((a, b) => a + b) / dataArray.length;
                    const open = 135 + (avg / 3); // De 'Q' waarde voor de mond-curve
                    mouth.setAttribute('d', `M 70 135 Q 100 ${open} 130 135`);
                    requestAnimationFrame(loop);
                }
                loop();
            }

            function animateMouthFromPhoneme(phoneme) {
                // optional: simple mouth pulse
                mouth.setAttribute('d', `M 70 135 Q 100 150 130 135`);
            }


            // Helper om Base64 audio van OpenAI af te spelen
            function playAndVisualize(base64Audio) {
                if (!audioCtx || !analyser) return;
                // 1. Converteer Base64 naar een ArrayBuffer
                const binaryString = atob(base64Audio);
                const len = binaryString.length;
                const bytes = new Int16Array(len / 2);
                for (let i = 0; i < len; i += 2) {
                    bytes[i / 2] = (binaryString.charCodeAt(i + 1) << 8) | binaryString.charCodeAt(i);
                }

                // 2. Converteer Int16 PCM naar Float32 (wat Web Audio nodig heeft)
                const float32Data = new Float32Array(bytes.length);
                for (let i = 0; i < bytes.length; i++) {
                    float32Data[i] = bytes[i] / 32768.0;
                }

                // 3. Maak een AudioBuffer (OpenAI Realtime stuurt standaard 24kHz mono)
                const audioBuffer = audioCtx.createBuffer(1, float32Data.length, 24000);
                audioBuffer.getChannelData(0).set(float32Data);

                // 4. Maak de Audio Source en verbind met de Analyser
                const source = audioCtx.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(analyser); // Dit zorgt ervoor dat de mond beweegt!
                // analyser is already connected to gainNode -> destination
                // 5. Plan het afspelen in (vloeiende overgang tussen chunks)
                const currentTime = audioCtx.currentTime;
                if (nextStartTime < currentTime) nextStartTime = currentTime;
                source.start(nextStartTime);
                nextStartTime += audioBuffer.duration;
            }

            // Transcript helper
            function appendTranscript(text, role = 'assistant') {
                let t = window._transcript || document.getElementById('transcript');
                if (!t) return;
                const p = document.createElement('div');
                p.textContent = text;
                p.className = role === 'user' ? 'text-right text-sky-300' : 'text-left text-cyan-200';
                t.appendChild(p);
                t.scrollTop = t.scrollHeight;
            }

            // Try to extract text from various message shapes
            function extractTextFromMessage(msg) {
                if (!msg) return null;
                if (msg.delta && (msg.delta.content || msg.delta.text)) return msg.delta.content || msg.delta.text;
                if (msg.audio_transcript && (msg.audio_transcript.text || msg.audio_transcript.content)) return msg.audio_transcript.text || msg.audio_transcript.content;
                if (msg.content_part && msg.content_part.text) return msg.content_part.text;
                if (msg.message && msg.message.content && Array.isArray(msg.message.content)) {
                    return msg.message.content.map((c) => (typeof c === 'string' ? c : c?.text)).filter(Boolean).join(' ');
                }
                if (msg?.delta?.content && Array.isArray(msg.delta.content)) {
                    // try to pull text from structured content
                    for (const c of msg.delta.content) {
                        if (typeof c === 'string') return c;
                        if (c?.text) return c.text;
                    }
                }
                if (msg?.response?.content && Array.isArray(msg.response.content)) {
                    for (const c of msg.response.content) {
                        if (typeof c === 'string') return c;
                        if (c?.text) return c.text;
                    }
                }
                if (msg.output && msg.output_text) return msg.output_text;
                if (msg.output_items && Array.isArray(msg.output_items)) {
                    for (const item of msg.output_items) {
                        if (item?.content) {
                            const text = Array.isArray(item.content)
                                ? item.content.map((c) => (typeof c === 'string' ? c : c?.text)).filter(Boolean).join(' ')
                                : (typeof item.content === 'string' ? item.content : item.content?.text);
                            if (text) return text;
                        }
                        if (item?.text) return item.text;
                    }
                }
                if (msg.text) return msg.text;
                if (msg.response && msg.response.output_text) return msg.response.output_text;
                if (msg.response && msg.response.output && Array.isArray(msg.response.output)) {
                    // common structured output
                    const parts = msg.response.output.map(p => (p?.content || p?.text || p)).filter(Boolean);
                    if (parts.length) return parts.join(' ');
                }
                // fallback: look for any property with string value
                for (const k of Object.keys(msg)) {
                    if (typeof msg[k] === 'string' && msg[k].trim()) return msg[k];
                }
                return null;
            }

            // Controls: disconnect, reconnect, mute
            function disconnectWS() {
                try {
                    if (ws) {
                        ws.close();
                        ws = null;
                    }
                } catch (e) { console.warn(e); }
                status.innerText = 'Disconnected';
                const startBtn = document.getElementById('start-btn');
                startBtn.classList.remove('hidden');
                startBtn.disabled = false;
                // clear TTL timer when disconnected
                if (ttlInterval) {
                    clearInterval(ttlInterval);
                    ttlInterval = null;
                }
                updateConnectionState('disconnected');
            }

            function reconnectWS() {
                disconnectWS();
                initCore();
            }

            function toggleMute() {
                muted = !muted;
                if (gainNode) gainNode.gain.value = muted ? 0 : 1;
                const btn = document.getElementById('mute-btn');
                if (btn) btn.textContent = muted ? 'Unmute' : 'Mute';
            }

            // Send user text input to the Realtime API via websocket
            function sendUserInput(text) {
                if (!ws || ws.readyState !== 1) {
                    status.innerText = 'Not connected';
                    return;
                }
                if (!text || !text.trim()) return;
                // Show user in transcript
                appendTranscript(text, 'user');
                const sessionInstructions = window._sessionData?.instructions;
                // The Realtime API expects `response.input` to be an ARRAY of input items.
                // Each input item can have a role and a structured content array.
                // The Realtime API expects input items with type 'message'.
                // Each message contains a content array; use a simple text content item.
                const event = {
                    type: 'response.create',
                    response: {
                        modalities: ['audio', 'text'],
                        instructions: sessionInstructions || undefined,

                        audio: {
                            voice: "shimmer",
                            format: "pcm16",
                            sample_rate: 24000
                        },
                        speech: {
                            phoneme_timestamps: true
                        },

                        input: [
                            {
                                type: 'message',
                                role: 'user',
                                content: [
                                    { type: 'input_text', text: text }
                                ]
                            }
                        ],
                    }
                };
                ws.send(JSON.stringify(event));
            }

            // Wire input field Enter to send
            try {
                const inputEl = document.getElementById('input-field');
                if (inputEl) {
                    inputEl.addEventListener('keydown', (ev) => {
                        if (ev.key === 'Enter') {
                            ev.preventDefault();
                            const v = inputEl.value;
                            inputEl.value = '';
                            sendUserInput(v);
                        }
                    });
                }
            } catch (e) { console.warn(e); }

            // Simple SpeechRecognition integration (if available)
            let recognition = null;
            let listening = false;
            function toggleMic() {
                if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                    alert('SpeechRecognition not supported in this browser');
                    return;
                }
                const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
                if (!recognition) {
                    recognition = new SR();
                    recognition.lang = 'nl-NL';
                    recognition.interimResults = false;
                    recognition.maxAlternatives = 1;
                    recognition.onresult = (e) => {
                        const text = e.results[0][0].transcript;
                        appendTranscript(text, 'user');
                        sendUserInput(text);
                    };
                    recognition.onerror = (e) => console.warn('SpeechRecognition error', e);
                    recognition.onend = () => { listening = false; updateMicUI(); };
                }
                if (!listening) {
                    recognition.start();
                    listening = true;
                } else {
                    recognition.stop();
                    listening = false;
                }
                updateMicUI();
            }

            function updateMicUI() {
                const mic = document.getElementById('mic-btn');
                if (!mic) return;
                mic.textContent = listening ? 'üéôÔ∏è' : 'üé§';
                mic.classList.toggle('bg-red-600/30', listening);
            }

            try {
                document.getElementById('mic-btn')?.addEventListener('click', toggleMic);
            } catch (e) { }

            // Connection state/TTL helpers
            function updateConnectionState(state) {
                const el = document.getElementById('conn-state');
                if (!el) return;
                el.textContent = `conn: ${state}`;
                el.className = state === 'connected' ? 'text-[10px] text-green-300' : state === 'error' ? 'text-[10px] text-red-400' : 'text-[10px] text-cyan-300';
            }

            function startTTLTimer(untilMs) {
                const el = document.getElementById('ttl-indicator');
                if (!el) return;
                if (ttlInterval) clearInterval(ttlInterval);
                function update() {
                    const now = Date.now();
                    const remaining = Math.max(0, Math.floor((untilMs - now) / 1000));
                    if (remaining <= 0) {
                        el.textContent = 'ttl: expired';
                        clearInterval(ttlInterval);
                        ttlInterval = null;
                    } else {
                        const m = Math.floor(remaining / 60);
                        const s = remaining % 60;
                        el.textContent = `ttl: ${m}m ${s}s`;
                    }
                }
                update();
                ttlInterval = setInterval(update, 1000);
            }

            // Wire control buttons
            try {
                const d = document.getElementById('disconnect-btn');
                const r = document.getElementById('reconnect-btn');
                const m = document.getElementById('mute-btn');
                if (d) d.addEventListener('click', disconnectWS);
                if (r) r.addEventListener('click', reconnectWS);
                if (m) m.addEventListener('click', toggleMute);
            } catch (e) {
                console.warn('Failed to wire control buttons', e);
            }
        }
    </script>
</body>

</html>